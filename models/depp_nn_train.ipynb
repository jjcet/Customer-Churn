{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johny\\ChurnProject\\Customer-Churn\n",
      "c:\\Users\\johny\\ChurnProject\\Customer-Churn\\data\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd \"../\"\n",
    "%cd \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    " \n",
    "  def __init__(self,split):\n",
    "    X = pd.read_csv(f\"X_{split}.csv\")\n",
    "    y = pd.read_csv(f\"y_{split}.csv\")\n",
    "\n",
    "    self.input_size = X.shape[1]\n",
    "\n",
    "    self.x=torch.tensor(X.values,dtype=torch.float32)\n",
    "    self.y=torch.tensor(y.values,dtype=torch.long).view(-1)\n",
    "    print(self.x.shape, self.y.shape)\n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.y)\n",
    "  \n",
    "   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5625, 35]) torch.Size([5625])\n",
      "torch.Size([1407, 35]) torch.Size([1407])\n"
     ]
    }
   ],
   "source": [
    "training_set=MyDataset(split=\"train\")\n",
    "validation_set=MyDataset(split=\"test\") \n",
    "training_loader=DataLoader(training_set, batch_size=80, shuffle=True)\n",
    "validation_loader=DataLoader(validation_set,batch_size=80,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 5625 instances\n",
      "Input vector size set has length of 35 \n",
      "Validation set has 1407 instances\n"
     ]
    }
   ],
   "source": [
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Input vector size set has length of {} '.format(training_set.input_size))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnClassifier(nn.Module):\n",
    "    def __init__(self, input_length, num_classes):\n",
    "        super(ChurnClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_length, 120)\n",
    "        self.fc2 = nn.Linear(120, 120)\n",
    "        self.fc3 = nn.Linear(120, 120)\n",
    "        self.fc4 = nn.Linear(120, 50)\n",
    "        self.fc5 = nn.Linear(50, 10)\n",
    "        self.fc6 = nn.Linear(10, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc6(x)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = self.loss(x, targets)\n",
    "        return x, loss\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\tdevice = \"cuda:0\"\n",
    "else:\n",
    "\tdevice = \"cpu\"\n",
    "\n",
    "\n",
    "model = ChurnClassifier(input_length=training_set.input_size, num_classes=2)\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_memory = torch.cuda.memory_allocated() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs, loss = model(inputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report, item to ensure that we not store the computation graph\n",
    "        running_loss += loss.item()\n",
    "        del outputs, loss, inputs, labels\n",
    "\n",
    "    \n",
    "\n",
    "    last_loss = running_loss / (i + 1)\n",
    "\n",
    "            \n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.5898 LOSS valid: 0.5642   ACCURACY: 74.63%\n",
      "EPOCH 2:\n",
      "LOSS train 0.5815 LOSS valid: 0.5630   ACCURACY: 74.63%\n",
      "EPOCH 3:\n",
      "LOSS train 0.5822 LOSS valid: 0.5633   ACCURACY: 74.63%\n",
      "EPOCH 4:\n",
      "LOSS train 0.5796 LOSS valid: 0.5615   ACCURACY: 74.63%\n",
      "EPOCH 5:\n",
      "LOSS train 0.5781 LOSS valid: 0.5575   ACCURACY: 74.63%\n",
      "EPOCH 6:\n",
      "LOSS train 0.5719 LOSS valid: 0.5460   ACCURACY: 74.63%\n",
      "EPOCH 7:\n",
      "LOSS train 0.5448 LOSS valid: 0.4958   ACCURACY: 74.63%\n",
      "EPOCH 8:\n",
      "LOSS train 0.4807 LOSS valid: 0.4350   ACCURACY: 74.63%\n",
      "EPOCH 9:\n",
      "LOSS train 0.4428 LOSS valid: 0.4208   ACCURACY: 77.83%\n",
      "EPOCH 10:\n",
      "LOSS train 0.4308 LOSS valid: 0.4347   ACCURACY: 77.54%\n",
      "EPOCH 11:\n",
      "LOSS train 0.4294 LOSS valid: 0.4176   ACCURACY: 78.96%\n",
      "EPOCH 12:\n",
      "LOSS train 0.4231 LOSS valid: 0.4184   ACCURACY: 78.89%\n",
      "EPOCH 13:\n",
      "LOSS train 0.4217 LOSS valid: 0.4227   ACCURACY: 78.32%\n",
      "EPOCH 14:\n",
      "LOSS train 0.4172 LOSS valid: 0.4348   ACCURACY: 77.83%\n",
      "EPOCH 15:\n",
      "LOSS train 0.4212 LOSS valid: 0.4279   ACCURACY: 78.46%\n",
      "EPOCH 16:\n",
      "LOSS train 0.4179 LOSS valid: 0.4535   ACCURACY: 76.83%\n",
      "EPOCH 17:\n",
      "LOSS train 0.4135 LOSS valid: 0.4257   ACCURACY: 78.68%\n",
      "EPOCH 18:\n",
      "LOSS train 0.4134 LOSS valid: 0.4194   ACCURACY: 79.10%\n",
      "EPOCH 19:\n",
      "LOSS train 0.4174 LOSS valid: 0.4261   ACCURACY: 78.61%\n",
      "EPOCH 20:\n",
      "LOSS train 0.4127 LOSS valid: 0.4260   ACCURACY: 78.32%\n",
      "EPOCH 21:\n",
      "LOSS train 0.4104 LOSS valid: 0.4194   ACCURACY: 79.18%\n",
      "EPOCH 22:\n",
      "LOSS train 0.4146 LOSS valid: 0.4318   ACCURACY: 77.90%\n",
      "EPOCH 23:\n",
      "LOSS train 0.4098 LOSS valid: 0.4203   ACCURACY: 78.18%\n",
      "EPOCH 24:\n",
      "LOSS train 0.4114 LOSS valid: 0.4223   ACCURACY: 78.61%\n",
      "EPOCH 25:\n",
      "LOSS train 0.4147 LOSS valid: 0.4212   ACCURACY: 79.32%\n",
      "EPOCH 26:\n",
      "LOSS train 0.4168 LOSS valid: 0.4176   ACCURACY: 78.61%\n",
      "EPOCH 27:\n",
      "LOSS train 0.4075 LOSS valid: 0.4204   ACCURACY: 79.32%\n",
      "EPOCH 28:\n",
      "LOSS train 0.4131 LOSS valid: 0.4180   ACCURACY: 79.67%\n",
      "EPOCH 29:\n",
      "LOSS train 0.4064 LOSS valid: 0.4286   ACCURACY: 78.25%\n",
      "EPOCH 30:\n",
      "LOSS train 0.4102 LOSS valid: 0.4394   ACCURACY: 77.33%\n",
      "EPOCH 31:\n",
      "LOSS train 0.4053 LOSS valid: 0.4243   ACCURACY: 78.75%\n",
      "EPOCH 32:\n",
      "LOSS train 0.4062 LOSS valid: 0.4210   ACCURACY: 78.75%\n",
      "EPOCH 33:\n",
      "LOSS train 0.4076 LOSS valid: 0.4213   ACCURACY: 79.67%\n",
      "EPOCH 34:\n",
      "LOSS train 0.4074 LOSS valid: 0.4452   ACCURACY: 78.11%\n",
      "EPOCH 35:\n",
      "LOSS train 0.4128 LOSS valid: 0.4236   ACCURACY: 78.89%\n",
      "EPOCH 36:\n",
      "LOSS train 0.4060 LOSS valid: 0.4243   ACCURACY: 79.25%\n",
      "EPOCH 37:\n",
      "LOSS train 0.4066 LOSS valid: 0.4233   ACCURACY: 79.46%\n",
      "EPOCH 38:\n",
      "LOSS train 0.4014 LOSS valid: 0.4290   ACCURACY: 78.32%\n",
      "EPOCH 39:\n",
      "LOSS train 0.4018 LOSS valid: 0.4251   ACCURACY: 78.61%\n",
      "EPOCH 40:\n",
      "LOSS train 0.4054 LOSS valid: 0.4347   ACCURACY: 77.61%\n",
      "EPOCH 41:\n",
      "LOSS train 0.4037 LOSS valid: 0.4238   ACCURACY: 78.82%\n",
      "EPOCH 42:\n",
      "LOSS train 0.3991 LOSS valid: 0.4345   ACCURACY: 78.25%\n",
      "EPOCH 43:\n",
      "LOSS train 0.3951 LOSS valid: 0.4276   ACCURACY: 78.75%\n",
      "EPOCH 44:\n",
      "LOSS train 0.3966 LOSS valid: 0.4366   ACCURACY: 78.11%\n",
      "EPOCH 45:\n",
      "LOSS train 0.3983 LOSS valid: 0.4268   ACCURACY: 78.75%\n",
      "EPOCH 46:\n",
      "LOSS train 0.3957 LOSS valid: 0.4491   ACCURACY: 77.04%\n",
      "EPOCH 47:\n",
      "LOSS train 0.3945 LOSS valid: 0.4342   ACCURACY: 78.61%\n",
      "EPOCH 48:\n",
      "LOSS train 0.4002 LOSS valid: 0.4265   ACCURACY: 78.82%\n",
      "EPOCH 49:\n",
      "LOSS train 0.3922 LOSS valid: 0.4297   ACCURACY: 78.82%\n",
      "EPOCH 50:\n",
      "LOSS train 0.3947 LOSS valid: 0.4352   ACCURACY: 78.75%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "epoch_number = 0\n",
    "\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    correct_predictions = 0  # Initialize the count of correct predictions\n",
    "    total_samples = 0  # Initialize the count of total validation samples\n",
    "\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "            voutputs, vloss = model(vinputs, vlabels)\n",
    "            running_vloss += vloss.item()\n",
    "            voutputs, vlabels = voutputs.cpu(), vlabels.cpu()\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(voutputs, 1)\n",
    "            correct_predictions += (predicted == vlabels).sum().item()\n",
    "            total_samples += vlabels.size(0)\n",
    "            del vinputs, vlabels, vloss, voutputs\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    accuracy = correct_predictions / total_samples \n",
    "    print('LOSS train {:.4f} LOSS valid: {:.4f}   ACCURACY: {:.2%}'.format(avg_loss, avg_vloss, accuracy))\n",
    "\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CustomerChurn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
